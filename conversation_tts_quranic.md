# Guide Complet - Entra√Ænement TTS Coqui/XTTS-v2 pour R√©citation Coranique

## Question Initiale
**Comment je puisse entra√Æner TTS Coqui que j'ai install√© dans mon serveur VPS pour avoir diff√©rentes voix ?**

## Partie 1 : Guide G√©n√©ral pour Coqui TTS

### 1. Fine-tuning d'un mod√®le existant (Recommand√© pour d√©buter)

C'est l'approche la plus simple et rapide :

```bash
# Installer Coqui TTS si ce n'est pas d√©j√† fait
pip install TTS

# T√©l√©charger un mod√®le pr√©-entra√Æn√© comme base
tts --list_models
```

#### Pr√©parer vos donn√©es audio
- **Format requis** : WAV mono, 22050 Hz ou 16000 Hz
- **Dur√©e** : Au minimum 30 minutes d'audio de qualit√©
- **Transcriptions** : Fichier texte avec transcriptions exactes

Structure des fichiers :
```
dataset/
‚îú‚îÄ‚îÄ wavs/
‚îÇ   ‚îú‚îÄ‚îÄ audio_001.wav
‚îÇ   ‚îú‚îÄ‚îÄ audio_002.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ metadata.csv
```

Le `metadata.csv` doit contenir :
```
audio_001|Texte de l'audio 001
audio_002|Texte de l'audio 002
```

### 2. Utiliser XTTS pour le clonage de voix

XTTS permet de cloner une voix avec seulement quelques secondes d'audio :

```python
from TTS.api import TTS

# Initialiser XTTS
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# Cloner une voix
tts.tts_to_file(
    text="Votre texte ici",
    file_path="output.wav",
    speaker_wav="chemin/vers/echantillon_voix.wav",
    language="fr"
)
```

### 3. Entra√Ænement complet avec VITS

Pour un contr√¥le total, cr√©ez un fichier de configuration :

```python
# config.json pour VITS
{
    "model": "vits",
    "run_name": "ma_voix_custom",
    "dataset": {
        "name": "ljspeech",
        "path": "/chemin/vers/dataset/",
        "meta_file_train": "metadata.csv",
        "language": "fr"
    },
    "audio": {
        "sample_rate": 22050,
        "max_wav_value": 32768.0,
        "num_mels": 80,
        "num_freq": 1025
    },
    "training": {
        "epochs": 1000,
        "batch_size": 16,
        "eval_batch_size": 8,
        "learning_rate": 0.0002
    }
}
```

Lancer l'entra√Ænement :
```bash
python TTS/bin/train_tts.py --config_path config.json
```

### 4. YourTTS pour multi-locuteurs

Pour entra√Æner un mod√®le avec plusieurs voix :

```bash
# Structure pour multi-locuteurs
dataset/
‚îú‚îÄ‚îÄ speaker1/
‚îÇ   ‚îú‚îÄ‚îÄ wavs/
‚îÇ   ‚îî‚îÄ‚îÄ metadata.csv
‚îú‚îÄ‚îÄ speaker2/
‚îÇ   ‚îú‚îÄ‚îÄ wavs/
‚îÇ   ‚îî‚îÄ‚îÄ metadata.csv
‚îî‚îÄ‚îÄ speakers.json
```

### 5. Optimisation pour VPS

Sur un VPS avec ressources limit√©es :

```python
# R√©duire la taille du batch
"batch_size": 4,

# Utiliser mixed precision
"mixed_precision": true,

# Gradient accumulation
"grad_accum_steps": 4,

# Checkpoint fr√©quent
"save_step": 500
```

### Commandes utiles

```bash
# Monitoring de l'entra√Ænement
tensorboard --logdir=output/logs

# Tester le mod√®le
tts --model_path checkpoint.pth \
    --config_path config.json \
    --text "Test de ma nouvelle voix" \
    --out_path test.wav

# Convertir en format optimis√©
python TTS/bin/convert_model.py \
    --model_path best_model.pth \
    --output_path model_optimized.pth
```

### Conseils pratiques

1. **Qualit√© audio** : Utilisez des enregistrements sans bruit de fond
2. **Coh√©rence** : Gardez le m√™me ton et rythme dans les enregistrements
3. **GPU** : Si possible, utilisez un VPS avec GPU (r√©duction du temps d'entra√Ænement de 10x)
4. **Sauvegarde** : Faites des checkpoints r√©guliers en cas d'interruption

---

## Partie 2 : XTTS-v2 Install√© et Fonctionnel

### 1. Clonage rapide de voix avec XTTS-v2

XTTS-v2 excelle dans le clonage de voix avec peu de donn√©es. Voici comment cr√©er plusieurs voix :

#### M√©thode simple - Clonage direct :

```python
import torch
from TTS.api import TTS

# Charger XTTS-v2
device = "cuda" if torch.cuda.is_available() else "cpu"
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

# Cr√©er diff√©rentes voix
voices = {
    "voix1": "samples/personne1.wav",
    "voix2": "samples/personne2.wav",
    "voix3": "samples/personne3.wav"
}

# G√©n√©rer avec diff√©rentes voix
for voice_name, voice_path in voices.items():
    tts.tts_to_file(
        text="Bonjour, ceci est un test de ma voix",
        speaker_wav=voice_path,
        language="fr",
        file_path=f"output_{voice_name}.wav"
    )
```

### 2. Pr√©parer vos √©chantillons de voix

Pour de meilleurs r√©sultats avec XTTS-v2 :

```bash
# Structure recommand√©e
voix_samples/
‚îú‚îÄ‚îÄ homme_jeune/
‚îÇ   ‚îú‚îÄ‚îÄ sample_1.wav  # 6-15 secondes
‚îÇ   ‚îú‚îÄ‚îÄ sample_2.wav
‚îÇ   ‚îî‚îÄ‚îÄ sample_3.wav
‚îú‚îÄ‚îÄ femme_senior/
‚îÇ   ‚îî‚îÄ‚îÄ sample.wav
‚îî‚îÄ‚îÄ voix_neutre/
    ‚îî‚îÄ‚îÄ sample.wav
```

#### Script de pr√©paration audio :
```python
import torchaudio
import torch

def prepare_voice_sample(input_path, output_path):
    """Pr√©pare un √©chantillon pour XTTS-v2"""
    
    # Charger l'audio
    waveform, sample_rate = torchaudio.load(input_path)
    
    # Convertir en mono si n√©cessaire
    if waveform.shape[0] > 1:
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    # Resampler √† 22050 Hz (recommand√© pour XTTS-v2)
    if sample_rate != 22050:
        resampler = torchaudio.transforms.Resample(sample_rate, 22050)
        waveform = resampler(waveform)
    
    # Normaliser
    waveform = waveform / waveform.abs().max()
    
    # Sauvegarder
    torchaudio.save(output_path, waveform, 22050)
    
# Utilisation
prepare_voice_sample("raw_voice.wav", "prepared_voice.wav")
```

### 3. Fine-tuning XTTS-v2 (Avanc√©)

Pour adapter XTTS-v2 √† une voix sp√©cifique :

```python
# config_ft.json pour fine-tuning
{
    "output_path": "output/xtts_ft/",
    "model_args": {
        "gpt_model_path": "path/to/xtts_v2/model.pth",
        "speaker_wav": "path/to/target_voice/",
        "language": "fr"
    },
    "dataset": {
        "path": "datasets/ma_voix/",
        "meta_file": "metadata.csv"
    },
    "train_params": {
        "batch_size": 2,  # Petit pour VPS
        "epochs": 50,
        "learning_rate": 5e-6,
        "gradient_accumulation_steps": 8
    }
}
```

Script de fine-tuning :
```python
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts

# Charger la config
config = XttsConfig()
config.load_json("config_ft.json")

# Initialiser le mod√®le
model = Xtts.init_from_config(config)
model.load_checkpoint(config, checkpoint_path="xtts_v2.pth")

# Fine-tuning
model.train()
# ... code d'entra√Ænement ...
```

### 4. API pour g√©rer plusieurs voix

Cr√©ez un serveur simple pour g√©rer vos voix :

```python
from fastapi import FastAPI, UploadFile
from TTS.api import TTS
import os
import json

app = FastAPI()
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# Base de donn√©es des voix
VOICES_DB = "voices_db.json"

def load_voices():
    if os.path.exists(VOICES_DB):
        with open(VOICES_DB, 'r') as f:
            return json.load(f)
    return {}

@app.post("/add_voice")
async def add_voice(name: str, file: UploadFile):
    """Ajouter une nouvelle voix"""
    
    # Sauvegarder l'√©chantillon
    voice_path = f"voices/{name}.wav"
    with open(voice_path, "wb") as f:
        f.write(await file.read())
    
    # Mettre √† jour la DB
    voices = load_voices()
    voices[name] = {
        "path": voice_path,
        "created": str(datetime.now())
    }
    
    with open(VOICES_DB, 'w') as f:
        json.dump(voices, f)
    
    return {"message": f"Voix '{name}' ajout√©e"}

@app.post("/synthesize")
async def synthesize(text: str, voice_name: str):
    """Synth√©tiser avec une voix sp√©cifique"""
    
    voices = load_voices()
    if voice_name not in voices:
        return {"error": "Voix non trouv√©e"}
    
    output_path = f"output_{int(time.time())}.wav"
    
    tts.tts_to_file(
        text=text,
        speaker_wav=voices[voice_name]["path"],
        language="fr",
        file_path=output_path
    )
    
    return {"audio_path": output_path}

# Lancer avec: uvicorn app:app --host 0.0.0.0 --port 8000
```

### 5. Optimisation pour VPS

```python
# R√©duire l'utilisation m√©moire
import torch

class XTTSOptimized:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
        
        if self.device == "cpu":
            # Mode CPU optimis√©
            torch.set_num_threads(4)
            self.tts.synthesizer.tts_model.half()  # FP16
    
    def generate(self, text, speaker_wav, language="fr"):
        with torch.no_grad():  # √âconomiser la m√©moire
            return self.tts.tts(
                text=text,
                speaker_wav=speaker_wav,
                language=language,
                temperature=0.7,  # Contr√¥le de la variation
                length_penalty=1.0,
                repetition_penalty=2.0,
                top_k=50,
                top_p=0.85
            )
```

### 6. Script batch pour cr√©er plusieurs voix

```bash
#!/bin/bash
# create_voices.sh

VOICES_DIR="./voices"
OUTPUT_DIR="./output"

for voice_file in $VOICES_DIR/*.wav; do
    voice_name=$(basename "$voice_file" .wav)
    echo "Traitement de $voice_name..."
    
    python -c "
from TTS.api import TTS
tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2')
tts.tts_to_file(
    text='Test de la voix $voice_name',
    speaker_wav='$voice_file',
    language='fr',
    file_path='$OUTPUT_DIR/test_$voice_name.wav'
)
"
done
```

### Conseils pratiques pour XTTS-v2

1. **Qualit√© des √©chantillons** : 6-15 secondes d'audio clair suffisent
2. **Format** : WAV 22050Hz mono pour de meilleurs r√©sultats
3. **Langue** : XTTS-v2 supporte le multilangue, sp√©cifiez toujours `language="fr"`
4. **M√©moire** : Sur VPS limit√©, traitez une voix √† la fois

---

## Partie 3 : Entra√Ænement pour la R√©citation Coranique

**Objectif** : Entra√Æner pour la lecture de texte coranique avec des voix de r√©citateurs comme Mishary Rashid, Abdul Rahman As-Sudais, Ali al-Hudhaify, Afif Mohammed Taj

### 1. Pr√©paration des √©chantillons de voix des r√©citateurs

#### Structure des dossiers :
```bash
quranic_reciters/
‚îú‚îÄ‚îÄ mishary_rashid/
‚îÇ   ‚îú‚îÄ‚îÄ sample.wav      # 10-20 secondes de r√©citation claire
‚îÇ   ‚îî‚îÄ‚îÄ backup/         # Plusieurs √©chantillons pour tests
‚îú‚îÄ‚îÄ sudais/
‚îÇ   ‚îú‚îÄ‚îÄ sample.wav
‚îÇ   ‚îî‚îÄ‚îÄ backup/
‚îú‚îÄ‚îÄ hudhaify/
‚îÇ   ‚îú‚îÄ‚îÄ sample.wav
‚îÇ   ‚îî‚îÄ‚îÄ backup/
‚îî‚îÄ‚îÄ afif_taj/
    ‚îú‚îÄ‚îÄ sample.wav
    ‚îî‚îÄ‚îÄ backup/
```

#### Script pour pr√©parer les √©chantillons audio :

```python
import os
import torch
import torchaudio
from pydub import AudioSegment
import numpy as np

class QuranicVoicePreparer:
    def __init__(self):
        self.target_sr = 22050  # Fr√©quence optimale pour XTTS-v2
        self.reciters = {
            "mishary_rashid": "Mishary Rashid Alafasy",
            "sudais": "Abdul Rahman As-Sudais", 
            "hudhaify": "Ali Al-Hudhaify",
            "afif_taj": "Afif Mohammed Taj"
        }
    
    def extract_best_segment(self, audio_path, output_path, start_sec=10, duration=15):
        """
        Extraire le meilleur segment pour XTTS-v2
        Entre 10-20 secondes de r√©citation claire
        """
        # Charger l'audio
        audio = AudioSegment.from_file(audio_path)
        
        # Convertir en mono et normaliser
        audio = audio.set_channels(1)
        audio = audio.set_frame_rate(self.target_sr)
        
        # Extraire le segment (√©viter d√©but/fin avec silence)
        start_ms = start_sec * 1000
        end_ms = start_ms + (duration * 1000)
        segment = audio[start_ms:end_ms]
        
        # Normaliser le volume
        segment = segment.normalize()
        
        # R√©duire le bruit de fond
        segment = segment.apply_gain(-segment.dBFS + (-20.0))
        segment = segment.normalize()
        
        # Sauvegarder
        segment.export(output_path, format="wav")
        print(f"‚úì √âchantillon pr√©par√©: {output_path}")
        return output_path
    
    def prepare_multiple_samples(self, source_audio, reciter_name, num_samples=3):
        """
        Cr√©er plusieurs √©chantillons d'un r√©citateur
        """
        output_dir = f"quranic_reciters/{reciter_name}"
        os.makedirs(f"{output_dir}/backup", exist_ok=True)
        
        audio = AudioSegment.from_file(source_audio)
        audio_duration = len(audio) / 1000  # en secondes
        
        samples = []
        
        # Extraire plusieurs segments
        for i in range(num_samples):
            start = min(i * 30 + 10, audio_duration - 20)
            
            if start + 15 <= audio_duration:
                output_path = f"{output_dir}/backup/sample_{i+1}.wav"
                self.extract_best_segment(
                    source_audio, 
                    output_path,
                    start_sec=start,
                    duration=15
                )
                samples.append(output_path)
        
        # Choisir le meilleur comme principal
        if samples:
            import shutil
            shutil.copy(samples[0], f"{output_dir}/sample.wav")
            
        return samples

# Utilisation
preparer = QuranicVoicePreparer()

# Pr√©parer les √©chantillons pour Mishary Rashid
preparer.prepare_multiple_samples(
    "source_audio/mishary_rahman.mp3",  # Audio source
    "mishary_rashid",
    num_samples=3
)
```

### 2. Clonage de voix avec XTTS-v2

```python
from TTS.api import TTS
import torch
import json
import os

class QuranicXTTS:
    def __init__(self):
        # Charger XTTS-v2
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Utilisation de: {self.device}")
        
        self.tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(self.device)
        
        # Configuration des r√©citateurs
        self.reciters_config = {
            "mishary_rashid": {
                "name": "Mishary Rashid Alafasy",
                "sample": "quranic_reciters/mishary_rashid/sample.wav",
                "speed": 0.9,          # Vitesse de r√©citation
                "temperature": 0.5,     # Stabilit√© de la voix
                "top_p": 0.85,         
                "top_k": 50
            },
            "sudais": {
                "name": "Abdul Rahman As-Sudais",
                "sample": "quranic_reciters/sudais/sample.wav",
                "speed": 0.85,
                "temperature": 0.45,
                "top_p": 0.8,
                "top_k": 50
            },
            "hudhaify": {
                "name": "Ali Al-Hudhaify",
                "sample": "quranic_reciters/hudhaify/sample.wav",
                "speed": 0.95,
                "temperature": 0.5,
                "top_p": 0.85,
                "top_k": 50
            },
            "afif_taj": {
                "name": "Afif Mohammed Taj",
                "sample": "quranic_reciters/afif_taj/sample.wav", 
                "speed": 0.88,
                "temperature": 0.55,
                "top_p": 0.85,
                "top_k": 50
            }
        }
    
    def synthesize_ayah(self, text, reciter="mishary_rashid", output_path=None):
        """
        Synth√©tiser une ayah avec la voix d'un r√©citateur
        """
        if reciter not in self.reciters_config:
            print(f"‚ùå R√©citateur '{reciter}' non disponible")
            return None
        
        config = self.reciters_config[reciter]
        print(f"üé§ G√©n√©ration avec la voix de {config['name']}...")
        
        # V√©rifier que l'√©chantillon existe
        if not os.path.exists(config['sample']):
            print(f"‚ùå √âchantillon manquant: {config['sample']}")
            return None
        
        # G√©n√©rer l'audio
        try:
            if output_path:
                self.tts.tts_to_file(
                    text=text,
                    speaker_wav=config['sample'],
                    language="ar",  # Arabe
                    file_path=output_path,
                    speed=config['speed'],
                    temperature=config['temperature'],
                    top_p=config['top_p'],
                    top_k=config['top_k']
                )
                print(f"‚úÖ Audio sauvegard√©: {output_path}")
                return output_path
            else:
                wav = self.tts.tts(
                    text=text,
                    speaker_wav=config['sample'],
                    language="ar",
                    speed=config['speed'],
                    temperature=config['temperature'],
                    top_p=config['top_p'],
                    top_k=config['top_k']
                )
                return wav
                
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
            return None
    
    def batch_synthesize(self, ayat_list, reciter="mishary_rashid"):
        """
        Synth√©tiser plusieurs ayat
        """
        output_dir = f"output/{reciter}"
        os.makedirs(output_dir, exist_ok=True)
        
        results = []
        for i, ayah in enumerate(ayat_list, 1):
            output_path = f"{output_dir}/ayah_{i:03d}.wav"
            result = self.synthesize_ayah(ayah, reciter, output_path)
            results.append(result)
            
        return results

# Utilisation
quranic_tts = QuranicXTTS()

# Test avec Sourate Al-Fatiha
ayat_fatiha = [
    "ÿ®Ÿêÿ≥ŸíŸÖŸê ÿßŸÑŸÑŸéŸëŸáŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸíŸÖŸéŸ∞ŸÜŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸêŸäŸÖŸê",
    "ÿßŸÑŸíÿ≠ŸéŸÖŸíÿØŸè ŸÑŸêŸÑŸéŸëŸáŸê ÿ±Ÿéÿ®ŸêŸë ÿßŸÑŸíÿπŸéÿßŸÑŸéŸÖŸêŸäŸÜŸé",
    "ÿßŸÑÿ±ŸéŸëÿ≠ŸíŸÖŸéŸ∞ŸÜŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸêŸäŸÖŸê",
    "ŸÖŸéÿßŸÑŸêŸÉŸê ŸäŸéŸàŸíŸÖŸê ÿßŸÑÿØŸêŸëŸäŸÜŸê",
    "ÿ•ŸêŸäŸéŸëÿßŸÉŸé ŸÜŸéÿπŸíÿ®ŸèÿØŸè ŸàŸéÿ•ŸêŸäŸéŸëÿßŸÉŸé ŸÜŸéÿ≥Ÿíÿ™ŸéÿπŸêŸäŸÜŸè",
    "ÿßŸáŸíÿØŸêŸÜŸéÿß ÿßŸÑÿµŸêŸëÿ±Ÿéÿßÿ∑Ÿé ÿßŸÑŸíŸÖŸèÿ≥Ÿíÿ™ŸéŸÇŸêŸäŸÖŸé",
    "ÿµŸêÿ±Ÿéÿßÿ∑Ÿé ÿßŸÑŸéŸëÿ∞ŸêŸäŸÜŸé ÿ£ŸéŸÜŸíÿπŸéŸÖŸíÿ™Ÿé ÿπŸéŸÑŸéŸäŸíŸáŸêŸÖŸí ÿ∫ŸéŸäŸíÿ±Ÿê ÿßŸÑŸíŸÖŸéÿ∫Ÿíÿ∂ŸèŸàÿ®Ÿê ÿπŸéŸÑŸéŸäŸíŸáŸêŸÖŸí ŸàŸéŸÑŸéÿß ÿßŸÑÿ∂ŸéŸëÿßŸÑŸêŸëŸäŸÜŸé"
]

# G√©n√©rer avec diff√©rents r√©citateurs
for reciter in ["mishary_rashid", "sudais", "hudhaify", "afif_taj"]:
    print(f"\nüìñ G√©n√©ration avec {reciter}...")
    quranic_tts.batch_synthesize(ayat_fatiha, reciter)
```

### 3. Optimisation pour VPS (ressources limit√©es)

```python
import gc
import torch

class OptimizedQuranicTTS:
    def __init__(self, low_memory=True):
        self.low_memory = low_memory
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        if low_memory and self.device == "cpu":
            # Mode √©conomie de m√©moire pour VPS
            torch.set_num_threads(2)
            torch.set_grad_enabled(False)
        
        # Charger le mod√®le une seule fois
        self.tts = None
        self.load_model()
    
    def load_model(self):
        """Charger le mod√®le avec optimisations"""
        if self.tts is None:
            print("‚è≥ Chargement du mod√®le XTTS-v2...")
            self.tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
            
            if self.low_memory:
                # Utiliser FP16 pour √©conomiser la m√©moire
                if hasattr(self.tts.synthesizer.tts_model, 'half'):
                    self.tts.synthesizer.tts_model.half()
                    
            self.tts.to(self.device)
            print("‚úÖ Mod√®le charg√©")
    
    def unload_model(self):
        """Lib√©rer la m√©moire"""
        if self.tts:
            del self.tts
            self.tts = None
            gc.collect()
            if self.device == "cuda":
                torch.cuda.empty_cache()
    
    def synthesize_with_memory_management(self, text, speaker_wav, output_path):
        """
        Synth√®se avec gestion de la m√©moire
        """
        try:
            # S'assurer que le mod√®le est charg√©
            if self.tts is None:
                self.load_model()
            
            # Synth√©tiser
            with torch.no_grad():
                self.tts.tts_to_file(
                    text=text,
                    speaker_wav=speaker_wav,
                    language="ar",
                    file_path=output_path,
                    speed=0.9
                )
            
            # Nettoyer la m√©moire apr√®s chaque g√©n√©ration si n√©cessaire
            if self.low_memory:
                gc.collect()
                
            return True
            
        except Exception as e:
            print(f"Erreur: {e}")
            return False
```

### 4. Script de d√©ploiement simple

```bash
#!/bin/bash
# deploy_quranic_tts.sh

# Cr√©er la structure des dossiers
mkdir -p quranic_reciters/{mishary_rashid,sudais,hudhaify,afif_taj}
mkdir -p output
mkdir -p source_audio

# Script Python pour tester
cat > test_quranic_tts.py << 'EOF'
from TTS.api import TTS
import sys

# Test simple
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")

# Texte de test (Bismillah)
text = "ÿ®Ÿêÿ≥ŸíŸÖŸê ÿßŸÑŸÑŸéŸëŸáŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸíŸÖŸéŸ∞ŸÜŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸêŸäŸÖŸê"

# R√©citateur par d√©faut (vous devez avoir l'√©chantillon)
speaker_wav = sys.argv[1] if len(sys.argv) > 1 else "quranic_reciters/mishary_rashid/sample.wav"

print(f"Test avec: {speaker_wav}")

tts.tts_to_file(
    text=text,
    speaker_wav=speaker_wav,
    language="ar",
    file_path="test_output.wav"
)

print("‚úÖ Test termin√©: test_output.wav")
EOF

# Lancer le test
python test_quranic_tts.py
```

### 5. Interface Web simple (FastAPI)

```python
# api_quranic.py
from fastapi import FastAPI, HTTPException, File, UploadFile
from fastapi.responses import FileResponse
from pydantic import BaseModel
import os

app = FastAPI(title="Quranic TTS API")

# Initialiser une fois au d√©marrage
from quranic_xtts import QuranicXTTS
tts_engine = QuranicXTTS()

class RecitationRequest(BaseModel):
    text: str
    reciter: str = "mishary_rashid"

@app.post("/recite/")
async def create_recitation(request: RecitationRequest):
    """Cr√©er une r√©citation"""
    
    output_file = f"output/recitation_{hash(request.text)}_{request.reciter}.wav"
    
    try:
        result = tts_engine.synthesize_ayah(
            text=request.text,
            reciter=request.reciter,
            output_path=output_file
        )
        
        if result:
            return {
                "status": "success",
                "file": output_file,
                "reciter": request.reciter
            }
        else:
            raise HTTPException(status_code=500, detail="√âchec de la g√©n√©ration")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/audio/{filename}")
async def get_audio(filename: str):
    """R√©cup√©rer un fichier audio"""
    file_path = f"output/{filename}"
    if os.path.exists(file_path):
        return FileResponse(file_path, media_type="audio/wav")
    raise HTTPException(status_code=404, detail="Fichier non trouv√©")

@app.post("/upload_sample/")
async def upload_reciter_sample(
    reciter: str,
    file: UploadFile = File(...)
):
    """Uploader un √©chantillon de r√©citateur"""
    
    # Sauvegarder l'√©chantillon
    save_path = f"quranic_reciters/{reciter}/sample.wav"
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    with open(save_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    return {"status": "success", "path": save_path}

# Lancer avec:
# uvicorn api_quranic:app --host 0.0.0.0 --port 8000 --workers 1
```

## Notes importantes finales

1. **√âchantillons** : 10-20 secondes de r√©citation claire suffisent pour XTTS-v2
2. **Format** : WAV 22050Hz mono recommand√©
3. **M√©moire** : ~2-4GB RAM n√©cessaire
4. **CPU vs GPU** : GPU 10x plus rapide, mais fonctionne sur CPU
5. **Qualit√©** : D√©pend fortement de la qualit√© de l'√©chantillon source
6. **Respect du tajweed** : Les r√®gles de r√©citation sont cruciales
7. **L√©galit√©** : Assurez-vous d'avoir les droits pour utiliser les enregistrements

---

*Document g√©n√©r√© √† partir de la conversation sur l'entra√Ænement de Coqui TTS/XTTS-v2 pour diff√©rentes voix et sp√©cifiquement pour la r√©citation coranique.*